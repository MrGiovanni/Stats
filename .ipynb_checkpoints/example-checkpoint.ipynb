{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f684615-b981-4502-94e2-840f8c2964ae",
   "metadata": {},
   "source": [
    "# Compute 95% CI (Confidence Intervals)\n",
    "#### 1. Classification examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9096a1d-f926-425c-8dc8-65974954514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 322.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score = 79.2 [95% CI: 77.6-80.8]\n",
      "precision_score = 90.9 [95% CI: 88.8-93.1]\n",
      "f1_score = 74.0 [95% CI: 71.5-76.4]\n",
      "sensitivity_score = 63.6 [95% CI: 60.7-66.5]\n",
      "specificity_score = 94.8 [95% CI: 93.7-96.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "from utils import *\n",
    "\n",
    "df = pd.read_csv('results/method1.csv')\n",
    "\n",
    "metrics = sampling_dataset(df['gt'], df['predict'])\n",
    "\n",
    "for metric_name in list(metrics.keys()):\n",
    "    lower, upper = st.t.interval(alpha=0.95, df=len(metrics[metric_name])-1, \n",
    "                                 loc=np.mean(metrics[metric_name]), \n",
    "                                 scale=st.sem(metrics[metric_name])) \n",
    "    print('{} = {:.1f} [95% CI: {:.1f}-{:.1f}]'.format(metric_name,\n",
    "                                                       np.mean(metrics[metric_name])*100,\n",
    "                                                       lower*100,\n",
    "                                                       upper*100,\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7762b0-7976-42c2-869c-f5f10b4118df",
   "metadata": {},
   "source": [
    "#### 2. Segmentation examples (e.g., Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbe2b95-ce55-486e-9b22-7e85fb72436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3005.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice = 80.6 [95% CI: 80.3-80.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "from utils import *\n",
    "\n",
    "df = pd.read_csv('results/dice1.csv')\n",
    "\n",
    "metric_name = 'dice'\n",
    "metrics = sampling_metrics(df[metric_name])\n",
    "\n",
    "lower, upper = st.t.interval(alpha=0.95, df=len(metrics)-1, \n",
    "                             loc=np.mean(metrics), \n",
    "                             scale=st.sem(metrics)) \n",
    "print('{} = {:.1f} [95% CI: {:.1f}-{:.1f}]'.format(metric_name,\n",
    "                                                   np.mean(metrics)*100,\n",
    "                                                   lower*100,\n",
    "                                                   upper*100,\n",
    "                                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ef77c-bb51-48d6-8dff-c397108fe319",
   "metadata": {},
   "source": [
    "# Perform t-test between two methods\n",
    "#### 1. Classification examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94b3ca9-9e62-4f96-900f-6176305aebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 327.99it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 332.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: p-value = 3.666751085859525e-46\n",
      "precision_score: p-value = 0.009914021800709827\n",
      "f1_score: p-value = 1.7812730328180964e-43\n",
      "sensitivity_score: p-value = 1.124461272966562e-56\n",
      "specificity_score: p-value = 0.9991139085712636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from utils import *\n",
    "\n",
    "df1 = pd.read_csv('results/method1.csv')\n",
    "df2 = pd.read_csv('results/method2.csv')\n",
    "assert len(df1) == len(df2)\n",
    "\n",
    "metrics1 = sampling_dataset(df1['gt'], df1['predict'])\n",
    "metrics2 = sampling_dataset(df2['gt'], df2['predict'])\n",
    "\n",
    "for metric_name in list(metrics1.keys()):\n",
    "    _, p = stats.ttest_ind(metrics1[metric_name], metrics2[metric_name])\n",
    "    print('{}: p-value = {}'.format(metric_name, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34bdb03-7f27-4500-b0b7-6a7375edd572",
   "metadata": {},
   "source": [
    "#### 2. Segmentation examples (e.g., Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613e6557-7352-4c74-8f8f-7c309de7313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3015.68it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2968.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice: p-value = 1.2958748749359716e-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from utils import *\n",
    "\n",
    "df1 = pd.read_csv('results/dice1.csv')\n",
    "df2 = pd.read_csv('results/dice2.csv')\n",
    "\n",
    "metric_name = 'dice'\n",
    "metrics1 = sampling_metrics(df1[metric_name])\n",
    "metrics2 = sampling_metrics(df2[metric_name])\n",
    "\n",
    "_, p = stats.ttest_ind(metrics1, metrics2)\n",
    "print('{}: p-value = {}'.format(metric_name, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
